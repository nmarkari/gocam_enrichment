{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e7e67aa-9640-415b-a9f6-9a36baecf9e0",
   "metadata": {},
   "source": [
    "## ncHGT.py code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2c9597-52e6-40e3-abab-56c9cd5e0678",
   "metadata": {},
   "outputs": [],
   "source": [
    "#let M = 5000, N = 200, m_gc = 30\n",
    "#between 170 and 200 entities could be sampled from the background\n",
    "#or 170 + 0 to 30 entities\n",
    "#as long as each M_i in M_array > 200, we can enumerate up to 30 for each slot and add to 170 without going over M_array for any index\n",
    "#solutions = 170 +enumerate([30,30,...30]) (and then filter such that sum(solutions, axis = 1)==N-k_ for each k_ greater than k\n",
    "#could actually enumerate for 30 - k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89bc2f2-a4d2-4d32-93bc-b7d6f39e418a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = (N-sum(m_gc))*np.ones(shape=(1,len(M_array))) #background could have between  and 0 slots\n",
    "m_bg_inverse = np.min(cap,M_array,axis=0)\n",
    "xt_bg = enumerate_possibilities_bg(m_bg_inverse,0,np.zeros(shape=(1,len(M_array)))) #all the ways to arrange empty slots (must be less than or equal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed2578c-b1f5-40b2-bc59-c7545bba4ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enumerate_bg(M_array, N, k, sum(m_gc))\n",
    "    XT_bg = []\n",
    "    if len(M_array) >2:\n",
    "        print('fast enumeration for bins > 2 not implemented')\n",
    "        return xt_bg = enumerate_possibilities(M_array,0,np.zeros(shape=(1,len(M_array)))) #all the ways the background could be sampled\n",
    "\n",
    "    for k_ in range(k,sum(m_gc)+1):\n",
    "        XT_bg_k = []\n",
    "        N_ = N-k_\n",
    "        print('k:',k)\n",
    "        x1 = np.arange(0,N_)\n",
    "        x2 = np.arange(0,N_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e4435834-d6c8-41db-9dd7-4df46903c9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('../GOCAM_Project/dev')\n",
    "\n",
    "import rpy2\n",
    "from rpy2.robjects.packages import importr\n",
    "BiasedUrn = importr('BiasedUrn')\n",
    "\n",
    "import utils\n",
    "\n",
    "def get_M_wM():\n",
    "    \"\"\" returns M, the number of entities in the background, and w_M, the mean size of entities in the background\"\"\"\n",
    "    setID2members = utils.csv2dict('../data/setID2members.csv')\n",
    "    l = []\n",
    "    for s,m in setID2members.items():\n",
    "        l.append(len(m))\n",
    "    l = np.array(l)\n",
    "    l = np.sort(l)\n",
    "    num_empty_sets = np.sum(l==0)\n",
    "    \n",
    "    l = l[l!=0]\n",
    "    mean = np.mean(l)#l[4:-4]) 1% trimmed mean?\n",
    "    num_sets = len(l)\n",
    "    bg = len(utils.csv2dict('../data/ID2gocam_mouse.csv'))\n",
    "    M = bg-num_empty_sets\n",
    "    \n",
    "    w_M = np.round(((M-num_sets)+num_sets*mean)/M,decimals=2)\n",
    "    return M, w_M\n",
    "\n",
    "def get_M_wM_XT_incorrect(num_bins = 1):\n",
    "    \"\"\" returns M, the number of entities in the background, and w_M, the mean size of entities in the background\"\"\"\n",
    "    setID2members = utils.csv2dict('../data/setID2members.csv')\n",
    "    bg_sets = []\n",
    "    for s,m in setID2members.items():\n",
    "        bg_sets.append(len(m))\n",
    "    bg_sets = np.array(bg_sets)\n",
    "    bg_sets = np.sort(bg_sets)\n",
    "    num_empty_sets = np.sum(bg_sets==0)\n",
    "    \n",
    "    bg_sets = bg_sets[bg_sets!=0]\n",
    "    num_sets = len(bg_sets)\n",
    "    len_bg_dict = len(utils.csv2dict('../data/ID2gocam_mouse.csv'))\n",
    "    M_weight_1 = len_bg_dict-num_empty_sets-num_sets #background = individual genes + empty sets + sets\n",
    "    bg = np.concatenate([bg_sets,np.ones(M_weight_1)]) #create a new l that also includes individual genes\n",
    "    \n",
    "    quantiles_ = np.quantile(bg,np.arange(num_bins+1)/num_bins)\n",
    "    quantiles_[0] = -np.inf\n",
    "    quantiles_[-1] = np.inf\n",
    "\n",
    "    w_M = []\n",
    "    M = []\n",
    "    for i in range(num_bins):\n",
    "        print('lower: ',quantiles_[i],' upper: ',quantiles_[i+1])\n",
    "        mask1 = bg >= quantiles_[i]\n",
    "        mask2 = bg <  quantiles_[i+1]\n",
    "        bg_ = bg[np.logical_and(mask1, mask2)]\n",
    "        print('bg_:',bg_)\n",
    "        w_M.append(round(np.mean(bg_),2))\n",
    "        M.append(len(bg_))\n",
    "    \n",
    "    \n",
    "    return M, w_M\n",
    "\n",
    "def get_M_wM_XT(num_bins = 1):\n",
    "    \"\"\" returns M, the number of entities in the background, and w_M, the mean size of entities in the background\"\"\"\n",
    "    setID2members = utils.csv2dict('../data/setID2members.csv')\n",
    "    bg_sets = []\n",
    "    for s,m in setID2members.items():\n",
    "        bg_sets.append(len(m))\n",
    "    bg_sets = np.array(bg_sets)\n",
    "    num_empty_sets = np.sum(bg_sets==0)\n",
    "    \n",
    "    bg_sets = bg_sets[bg_sets!=0]\n",
    "    num_sets = len(bg_sets)\n",
    "    len_bg_dict = len(utils.csv2dict('../data/ID2gocam_mouse.csv'))\n",
    "    M_weight_1 = len_bg_dict-num_empty_sets-num_sets #background = individual genes + empty sets + sets\n",
    "    bg = np.concatenate([np.ones(M_weight_1),bg_sets]) #create a new l that also includes individual genes\n",
    "\n",
    "    bg = np.sort(bg)\n",
    "\n",
    "    w_M = []\n",
    "    M = []\n",
    "    idx = 0\n",
    "    for i in range(num_bins):\n",
    "        bg_ = bg[idx:int(idx+len(bg)/num_bins)]\n",
    "        idx+=int(len(bg)/num_bins)\n",
    "        w_M.append(round(np.mean(bg_),2))\n",
    "        M.append(len(bg_))\n",
    "    \n",
    "    \n",
    "    return M, w_M\n",
    "\n",
    "def make_initial_vectors(gocam2ID,setID2members, gc, M,w_M):\n",
    "    \"\"\"initializes counts vector (m) and weights vector (w), where each entity gets its own element in the arrays\n",
    "- values in m only take on 0 (if there is no solo proteins) or 1\n",
    "- values in w correspond to the weight of each element in m (weighted by the # genes in a set or 1 for solo proteins)\"\"\"\n",
    "    w_gc = [1] #initialize with 1 as the weight of single proteins (irrespective of whether there are any)\n",
    "    m_gc = [0] #initialize with 0 single proteins\n",
    "    num_protein = 0\n",
    "    for i in gocam2ID.get(gc):\n",
    "        if \"sset:\" in i:\n",
    "            w_i = len(setID2members.get(i))\n",
    "            w_gc.append(w_i)\n",
    "            m_gc.append(1)\n",
    "        else:\n",
    "            num_protein+=1\n",
    "    m_gc[0] = num_protein\n",
    "    m_gc.append(M-np.sum(m_gc)) #entities not in the gocam (roughly)\n",
    "    w_gc.append(w_M) #weight for entities not in the gocam (all weighted as w_M (the mean))\n",
    "    return w_gc, m_gc\n",
    "\n",
    "\n",
    "def make_new_vectors(w_gc,m_gc,M,w_M):\n",
    "    \"\"\"compress the m and w vectors by grouping elements according to their weights\n",
    "- w is the ordered set of unique weights for entities of the gocam + the background bin\n",
    "- m[i] is the number of entities in the pathway with the weight specified in w[i] + the background bin\"\"\"\n",
    "    w_temp = w_gc[:-1]\n",
    "    if w_temp[0] != 1:\n",
    "        print('Possible bug: w_temp[0] != 1',w_temp)\n",
    "        \n",
    "    w_new, m_temp = np.unique(w_temp, return_counts=True)\n",
    "    m_temp[0]=m_gc[0] #w_gc and m_gc have weight 1 as w_gc[0] and the number of single proteins as m_gc[0]\n",
    "    m_new = np.append(m_temp,np.array([M-np.sum(m_temp)]))\n",
    "    w_new = np.append(np.unique(w_temp),np.array([w_M]))\n",
    "    return w_new, m_new\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def ncHGT_sf(XT,m,N,w):\n",
    "    \"\"\"survival function, sums PMF for all possibilities where K >= k by calling BiasedUrn\"\"\"\n",
    "    #l = len(XT)/len(m)\n",
    "    if len(XT) == 0:\n",
    "        print('len(XT) = 0')\n",
    "        return -1\n",
    "    pval = 0\n",
    "    #np.seterr(under='warn')\n",
    "    ### This could be optimized by setting a threshold and stopping the for loop when the sum exceeds some threshold###\n",
    "    i = 0\n",
    "    for xt in XT:\n",
    "        i+= 1\n",
    "        x = rpy2.robjects.IntVector(xt)\n",
    "        pval = pval + BiasedUrn.dMFNCHypergeo(x,m,N,w, precision = 1e-10)[0]\n",
    "        if len(XT) > 100000 and i % int(len(XT)/100) ==0:\n",
    "            print(f'{int(i/len(XT)*100)}% done out of {len(XT)} iterations')\n",
    "        elif len(XT) > 10000 and i % int(len(XT)/10) ==0:\n",
    "            print(f'{int(i/len(XT)*100)}% done out of {len(XT)} iterations')\n",
    "        \n",
    "    return pval\n",
    "\n",
    "import time\n",
    "\n",
    "def enumerate_possibilities(m_new,i,prev_array):\n",
    "    \"\"\"enumerate all possible counts vectors\"\"\"\n",
    "    \n",
    "    first = True\n",
    "    for j in range(m_new[i]+1):\n",
    "        xt = prev_array.copy()\n",
    "        xt[0][i] = j\n",
    "        \n",
    "        #recursion\n",
    "        if (i < len(m_new)-1):\n",
    "            xt = enumerate_possibilities(m_new, i+1, xt) #will return matrix (array of arrays)\n",
    "            \n",
    "        #combining results into matrix\n",
    "        if not first:\n",
    "            XT = np.concatenate([XT,xt], axis = 0)\n",
    "        else:\n",
    "            XT = xt\n",
    "            first = False\n",
    "    return XT\n",
    "\n",
    "\n",
    "def do_ncHGT(k,gc,M,N,bins =2):\n",
    "    setID2members = utils.csv2dict('../data/setID2members.csv')\n",
    "    gocam2ID = utils.csv2dict('../data/gocam2ID_mouse.csv')\n",
    "    \n",
    "    M, w_M = get_M_wM()\n",
    "    \n",
    "    #make weight (w) and bin size (m) vectors where each entity in the gocam gets its own entry\n",
    "    w_in, m_in = make_initial_vectors(gocam2ID, setID2members, gc, M,w_M)\n",
    "    \n",
    "    #update m and w vectors by grouping sets of the same size\n",
    "    w_new , m_new= make_new_vectors(w_in,m_in,M,w_M)\n",
    "\n",
    "    #make XT matrix, an enumeration of all possible arangements of balls in bins based on m_new and w_new\n",
    "    m_gc = m_new[:-1] #don't pass the background bin to XT\n",
    "    t0 = time.time()\n",
    "    XT = enumerate_possibilities(m_gc,0,np.zeros(shape=(1,len(m_gc))))\n",
    "    #print(f'time to enumerate: {round(time.time()-t0,3)}')\n",
    "    \n",
    "    #filter XT to only include the region of the sample space >= k (which is what we want to sum probabilities over)\n",
    "    mask1 = (np.sum(XT, axis=1) >= k)\n",
    "    XT = XT[mask1]\n",
    "\n",
    "    #filter XT to ensure that more than N entities are not picked\n",
    "    mask2 = (np.sum(XT, axis=1) <= N)\n",
    "    XT = XT[mask2]\n",
    "\n",
    "    #### MODIFIED CODE BELOW #####\n",
    "    #add the remaining entities to the m+1th bin (non gocam bin)\n",
    "    M_array, w_M_array = get_M_wM_XT(num_bins = bins)\n",
    "    #print(M_array)\n",
    "    #print(w_M_array)\n",
    "    \n",
    "    t0 = time.time()\n",
    "    #xt_bg = enumerate_bg(M_array, N, k, sum(m_gc))\n",
    "    xt_bg = enumerate_possibilities(N*np.ones(len(M_array),dtype = np.int32),0,np.zeros(shape=(1,len(M_array)))) #all the ways the background could be sampled\n",
    "    xt_bg = xt_bg[np.sum(xt_bg, axis=1) >= N-k]\n",
    "    xt_bg = xt_bg[np.sum(xt_bg, axis=1) <= N]\n",
    "    #print(M_array)\n",
    "    #print(k)\n",
    "    #print(sum(m_gc))\n",
    "    #print(xt_bg[:100])\n",
    "    #print(f'time to enumerate bg: {round(time.time()-t0,3)}')\n",
    "    XT_complete = []\n",
    "    for k_ in range(k,sum(m_gc)): #group by k\n",
    "        N_bg = N - k_\n",
    "        mask_bg = (np.sum(xt_bg, axis=1) == N_bg)\n",
    "        xt_bg_ = xt_bg[mask_bg]\n",
    "        XT_slice = XT[np.sum(XT, axis =1) == k_]\n",
    "        \n",
    "        xt_duplicated = np.tile(XT_slice,(len(xt_bg_),1))\n",
    "        xt_bg_duplicated = np.repeat(xt_bg_,len(XT_slice),axis = 0)\n",
    "\n",
    "        if len(XT_complete) == 0:\n",
    "            XT_complete = np.concatenate([xt_duplicated,xt_bg_duplicated],axis = 1)\n",
    "        else:\n",
    "            XT_complete = np.concatenate([XT_complete, (np.concatenate([xt_duplicated,xt_bg_duplicated],axis = 1))], axis = 0)\n",
    "    XT_complete = np.array(XT_complete)   \n",
    "    #x_mp1_vec = N- np.sum(XT, axis = 1) #number of balls to be drawn from the last bin (the non-gocam background)\n",
    "    #XT = np.concatenate((XT,x_mp1_vec.reshape(len(x_mp1_vec),1)), axis = 1)\n",
    "    \n",
    "    m_new = np.concatenate([m_new[:-1],M_array]) #overwrite the last entry in m_new (dedicated to the background) with  M_array\n",
    "    w_new = np.concatenate([w_new[:-1],w_M_array]) #overwrite the last entry in w_new (dedicated to the background) with w_M_array\n",
    "    ##### MODIFIED CODE ABOVE #####\n",
    "    \n",
    "    m = rpy2.robjects.IntVector(m_new)\n",
    "    w = rpy2.robjects.FloatVector(w_new)\n",
    "    #print(XT_complete)\n",
    "    #print()\n",
    "    #print()\n",
    "    #print(m_new)\n",
    "    #print(w_new)\n",
    "    t0 = time.time()\n",
    "    pval = ncHGT_sf(XT_complete,m,N,w)\n",
    "    #print(f'time to compute pval: {round(time.time()-t0,3)}')\n",
    "    return pval\n",
    "\n",
    "def do_ncHGT_old(k,gc,M,N,bins =2):\n",
    "    setID2members = utils.csv2dict('../data/setID2members.csv')\n",
    "    gocam2ID = utils.csv2dict('../data/gocam2ID_mouse.csv')\n",
    "    \n",
    "    M, w_M = get_M_wM()\n",
    "    \n",
    "    #make weight (w) and bin size (m) vectors where each entity in the gocam gets its own entry\n",
    "    w_in, m_in = make_initial_vectors(gocam2ID, setID2members, gc, M,w_M)\n",
    "    \n",
    "    #update m and w vectors by grouping sets of the same size\n",
    "    w_new , m_new= make_new_vectors(w_in,m_in,M,w_M)\n",
    "\n",
    "    #make XT matrix, an enumeration of all possible arangements of balls in bins based on m_new and w_new\n",
    "    m_gc = m_new[:-1] #don't pass the background bin to XT\n",
    "    t0 = time.time()\n",
    "    XT = enumerate_possibilities(m_gc,0,np.zeros(shape=(1,len(m_gc))))\n",
    "    print(f'time to enumerate: {round(time.time()-t0,3)}')\n",
    "    \n",
    "    #filter XT to only include the region of the sample space >= k (which is what we want to sum probabilities over)\n",
    "    mask1 = (np.sum(XT, axis=1) >= k)\n",
    "    XT = XT[mask1]\n",
    "\n",
    "    #filter XT to ensure that more than N entities are not picked\n",
    "    mask2 = (np.sum(XT, axis=1) <= N)\n",
    "    XT = XT[mask2]\n",
    "\n",
    "    #### MODIFIED CODE BELOW #####\n",
    "    #add the remaining entities to the m+1th bin (non gocam bin)\n",
    "    M_array, w_M_array = get_M_wM_XT(num_bins = bins)\n",
    "    #print(M_array)\n",
    "    #print(w_M_array)\n",
    "    t0 = time.time()\n",
    "    xt_bg = enumerate_possibilities(M_array,0,np.zeros(shape=(1,len(M_array)))) #all the ways the background could be sampled\n",
    "    print(f'time to enumerate bg: {round(time.time()-t0,3)}')\n",
    "    XT_complete = []\n",
    "    for k_ in range(k,sum(m_gc)): #group by k\n",
    "        N_bg = N - k_\n",
    "        mask_bg = (np.sum(xt_bg, axis=1) == N_bg)\n",
    "        xt_bg_ = xt_bg[mask_bg]\n",
    "        XT_slice = XT[np.sum(XT, axis =1) == k_]\n",
    "        xt_duplicated = np.tile(xt,(len(xt_bg_),1))\n",
    "        if len(XT_complete) == 0:\n",
    "            XT_complete = np.concatenate([xt_duplicated,np.repeat(xt_bg_,len(XT_slice),axis=0)],axis = 1)\n",
    "        else:\n",
    "            XT_complete = np.concatenate([XT_complete, (np.concatenate([xt_duplicated,np.repeat(xt_bg_,len(XT_slice),axis=0)],axis = 1))], axis = 0)\n",
    "            \n",
    "    XT_complete = np.array(XT_complete)   \n",
    "    #x_mp1_vec = N- np.sum(XT, axis = 1) #number of balls to be drawn from the last bin (the non-gocam background)\n",
    "    #XT = np.concatenate((XT,x_mp1_vec.reshape(len(x_mp1_vec),1)), axis = 1)\n",
    "    \n",
    "    m_new = np.concatenate([m_new[:-1],M_array]) #overwrite the last entry in m_new (dedicated to the background) with  M_array\n",
    "    w_new = np.concatenate([w_new[:-1],w_M_array]) #overwrite the last entry in w_new (dedicated to the background) with w_M_array\n",
    "    ##### MODIFIED CODE ABOVE #####\n",
    "    \n",
    "    m = rpy2.robjects.IntVector(m_new)\n",
    "    w = rpy2.robjects.FloatVector(w_new)\n",
    "    #print(XT_complete)\n",
    "    #print()\n",
    "    #print()\n",
    "    #print(m_new)\n",
    "    #print(w_new)\n",
    "    t0 = time.time()\n",
    "    pval = ncHGT_sf(XT_complete,m,N,w)\n",
    "    print(f'time to compute pval: {round(time.time()-t0,3)}')\n",
    "    return pval\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc1cd4a1-9489-4970-91ca-87244e1b3b58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [1, 2],\n",
       "       [3, 4],\n",
       "       [3, 4]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[1,2],[3,4]])\n",
    "np.repeat(x, 2, axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e476ca9-0e4c-40b8-bcdb-2456bec0a17c",
   "metadata": {},
   "source": [
    "Instead, I could make XT the enumeration over np.concatenate([m_gc,M_array]) and mask such that the gocam portion sums to >=k and the whole vector (axis = 1) sums to N"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f3aa10-9406-4f17-ad4c-e089136b34ab",
   "metadata": {
    "tags": []
   },
   "source": [
    "## enrich.py code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1c69815-ca68-4dc4-8764-be8ac739330e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "from scipy.stats import hypergeom\n",
    "import sys\n",
    "sys.path.append('../GOCAM_Project/dev')\n",
    "import os\n",
    "import tqdm\n",
    "\n",
    "import utils\n",
    "pd.options.display.max_colwidth = 100\n",
    "\n",
    "def get_sizes (data): #data= dataframe with gocam IDs and gene identifiers as columns\n",
    "    \"\"\"get number of entities in each gocam\"\"\"\n",
    "    return data['gocam'].value_counts()\n",
    "    \n",
    "def get_sets (gene_list):\n",
    "    \"\"\"map list of genes to all sets that contain members of that list\"\"\"\n",
    "    sets = []\n",
    "    not_in_a_set = []\n",
    "    members2setID = utils.csv2dict('../data/members2setID.csv')\n",
    "    setID2members_input = {}\n",
    "    for g in gene_list:\n",
    "        s = members2setID.get(g)\n",
    "        if s != None:\n",
    "            sets = sets +s\n",
    "            for i in s:\n",
    "                if (i in setID2members_input) == False:\n",
    "                    setID2members_input[i]={g}\n",
    "                else:\n",
    "                    prev = setID2members_input.get(i)\n",
    "                    prev.add(g)\n",
    "                    setID2members_input[i] = prev\n",
    "        else:\n",
    "            not_in_a_set.append(g)\n",
    "    return not_in_a_set, list(set(sets)),setID2members_input #remove duplicates\n",
    "\n",
    "def filter_gene_list(gene_list, Dict):\n",
    "    \"\"\"remove members of gene_list that are not in Dict.\n",
    "    use function to filter a user's input list of genes based on those that appear at least \n",
    "    once in the gocam model database\"\"\"\n",
    "    filtered_gene_list = []\n",
    "    filtered_out = []\n",
    "    for gene in gene_list:\n",
    "        if gene in Dict:\n",
    "            filtered_gene_list.append(gene)\n",
    "        else:\n",
    "            filtered_out.append(gene)\n",
    "    return filtered_out, filtered_gene_list\n",
    "\n",
    "def count_genes(gene_list, Dict):\n",
    "    \"\"\" count number of genes in user's gene_list that are in each gocam\"\"\"\n",
    "    gocam_counts = {} #key=gocam, value=list of genes in gocam that are also in the user's list\n",
    "    for g in gene_list: \n",
    "            gocams = Dict.get(g)\n",
    "            for gocam in gocams:\n",
    "                if (gocam in gocam_counts) == False:\n",
    "                    gocam_counts[gocam]=[g]\n",
    "                else:\n",
    "                    prev = gocam_counts.get(gocam)\n",
    "                    prev.append(g)\n",
    "                    gocam_counts[gocam] = prev\n",
    "    return gocam_counts\n",
    "\n",
    "#BENJAMINI HOCHBERG CORRECTION applied in correct_pval_and_format()\n",
    "#ncHGT is either False (indicating that regular HGT should be done) or a positive integer denoting N for ncHGT\n",
    "def hgt(counts, gocam_sizes, FDR, gene_list_size, background_gene_list_size, ncHGT = False, num_bins = 0):\n",
    "    \"\"\" performs either the hypergeometric test or our introduced test using Fisher's noncentral hypergeometric dist.\n",
    "    Whether our unweighted set enrichment or the standard HGT is performed is determined upstream based on what\n",
    "    Dict of gocams->entities and filtered gene_list are passed into count_genes().\n",
    "    ncHGT is either False (for set or standard methods) or corresponds to N \"\"\"\n",
    "    results = []\n",
    "    iterator = tqdm.tqdm(counts.items())\n",
    "    for gocam, gene_list in iterator:\n",
    "        count = len(gene_list) \n",
    "        gocam_size = gocam_sizes[gocam]\n",
    "        pvalue = None\n",
    "        if ncHGT:\n",
    "            if count <=1: #avoid unnecessary calls to BiasedUrn due to computation time\n",
    "                pvalue = 1\n",
    "            else:\n",
    "                pvalue = do_ncHGT(count -1,gocam,background_gene_list_size,ncHGT,bins = num_bins)\n",
    "        else: #set or standard methods\n",
    "            pvalue = hypergeom.sf(count-1, background_gene_list_size,  gocam_size, gene_list_size) \n",
    "        if pvalue < 1: #FDR:\n",
    "            r = (gocam, pvalue, count, gocam_size, gene_list )\n",
    "            results.append(r)\n",
    "    return results\n",
    "\n",
    "#Benjamini Hochberg correction\n",
    "def correct_pval_and_format(enriched_gocams, background_num_gocams,FDR):\n",
    "    \"\"\"performs Benjamini Hochberg correction to control the false discovery rate and formats output for display\"\"\"\n",
    "    df = pd.DataFrame(enriched_gocams, columns =['url', 'pval (uncorrected)', '# entities in list','#entities in model','shared entities in gocam'])\n",
    "    df.sort_values('pval (uncorrected)',inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    df['FDR_val'] = (df.index+1)*FDR/background_num_gocams\n",
    "    df['Less_than'] = (df['pval (uncorrected)'] < df['FDR_val'])\n",
    "    index = df.Less_than.where(df.Less_than==True).last_valid_index()\n",
    "    df_significant = df\n",
    "    \n",
    "    df_significant = df.loc[0:index].copy()\n",
    "    if index == None:\n",
    "        df_significant = pd.DataFrame(columns =['url', 'pval (uncorrected)', '# entities in list','#entities in model','shared entities in gocam'])\n",
    "    df_display = df_significant[['url','pval (uncorrected)', '# entities in list', '#entities in model','shared entities in gocam']].copy()\n",
    "    #modelID2title = pd.read_csv('../data/modelID2title_mouse.csv')\n",
    "    temp = pd.read_csv('../data/modelID2title_mouse.csv',header = 0,names=['gocam','title'])\n",
    "    modelID2title = pd.Series(temp.title.values,index=temp.gocam).to_dict()\n",
    "    df_display['title'] = df_display['url'].map(modelID2title)\n",
    "    cols = df_display.columns.to_list()\n",
    "    cols[0]='title'\n",
    "    cols[-1]='url'\n",
    "    df_display = df_display[cols]\n",
    "    return df_display\n",
    "\n",
    "#Dict can only contain 1 instance of each gene per gocam (no duplicates)\n",
    "def enrich(gene_list, uni_list,uniprot2input,gocam_sizes, Dict, ncHGT=False,FDR=.05, num_bins = 0):\n",
    "    \"\"\"uni_list is the list of uniprot IDs, because the backend dictionary, Dict, is gocam_id-> list(uniprot id's).\n",
    "    uniprot2input is a dictionary keeping track of which of the user's inputs mapped to which uniprot id's so results can be \n",
    "    displayed in the user's inputted format, as the mapping is not always 1:1.\"\"\"\n",
    "    background_gene_list_size = len(Dict)\n",
    "    if ncHGT: \n",
    "    #we consider the background size to be equal to the total # of genes \n",
    "    #(the sum of the weights of all entities would double count genes that occur in multiple sets\n",
    "    #... is this the right thing to do though?\n",
    "        background_gene_list_size = len(utils.csv2dict('../data/ID2gocam_mouse_ff.csv'))\n",
    "        \n",
    "    not_in_a_set, sets, setID2members_input_uni = get_sets(uni_list)\n",
    "    \n",
    "    setID2members_input = utils.map_dict_vals(uniprot2input, setID2members_input_uni)\n",
    "    \n",
    "    filtered_out1, set_list_filtered = filter_gene_list(sets,Dict)\n",
    "    filtered_out2, gene_list_filtered = filter_gene_list(uni_list, Dict) #need to clean gene_list to only include genes in the gocam\n",
    "    \n",
    "    \n",
    "    filtered_list = gene_list_filtered + set_list_filtered\n",
    "    gene_list_size = len(filtered_list)\n",
    "    \n",
    "    flist2input = {**uniprot2input, **setID2members_input}\n",
    "    filtered_list_as_genes = set(pd.Series(list(filtered_list)).map(flist2input).explode())\n",
    "    filtered_out_genes = set(gene_list) - filtered_list_as_genes\n",
    "    \n",
    "    counts = count_genes(filtered_list, Dict)\n",
    "    \n",
    "    N_ncHGT = False\n",
    "    if ncHGT == True:\n",
    "        N_ncHGT = len(gene_list)-len(filtered_out_genes)\n",
    "        if N_ncHGT <= 0:\n",
    "            return \"error no genes found in gocams\"\n",
    "        \n",
    "    enriched_gocams = hgt(counts, gocam_sizes, FDR, gene_list_size, background_gene_list_size, ncHGT=N_ncHGT, num_bins = num_bins)\n",
    "    background_num_gocams = len(gocam_sizes)\n",
    "    df_display = correct_pval_and_format(enriched_gocams, background_num_gocams,FDR)\n",
    "    return filtered_out_genes, filtered_list, setID2members_input_uni, setID2members_input, df_display\n",
    "    \n",
    "def enrich_wrapper(filename, id_type, method = 'set', return_all = False, FDR=.05,fpath= '../test_data', display_gene_symbol = True, num_bins = 1):\n",
    "    \"\"\" wrapper to perform enrichment given a filename, gene ID type, enrichment method, and false discovery rate.\n",
    "    other parameters:\n",
    "    \n",
    "    return_all: \n",
    "        if false, only returns the dataframe displaying results. \n",
    "        if true: returns (gene_list, filtered_out_genes, filtered_list, setID2members_input_uni, setID2members_input, df_display)\n",
    "        return_all = True is not just for debugging. User may want to know which of their input genes were filtered out as well as how\n",
    "        the IDs were mapped, as uniprot IDs can sometimes map to more than one HGNC gene symbol\n",
    "    display_gene_symbol: if true, display HGNC symbols on output regardless of input ID type\"\"\"\n",
    "        \n",
    "    #set method files\n",
    "    gcs = '../data/gocam_sizes_mouse.csv'\n",
    "    id2g = '../data/ID2gocam_mouse.csv'\n",
    "    \n",
    "    #standard method files\n",
    "    if method == 'standard':\n",
    "        gcs = '../data/gocam_sizes_mouse_ff.csv'\n",
    "        id2g = '../data/ID2gocam_mouse_ff.csv'\n",
    "    \n",
    "    gene_list = pd.read_csv(os.path.join(fpath,filename),header=None,names = ['g'])\n",
    "    \n",
    "    #normally not needed, but I found a bug where HSPA1A and HSPA1B are listed as synonyms, both in Simplemine and official sources like the Alliance\n",
    "    gene_list.drop_duplicates(inplace = True) \n",
    "    \n",
    "    gene_list_converted = []\n",
    "    uniprot2input = {}\n",
    "    not_converted = []\n",
    "    \n",
    "    #conversion to uniprot IDs not needed for a list of uniprot IDs\n",
    "    if id_type == 'uniprot':\n",
    "        gene_list_converted = gene_list.g\n",
    "        uniprot2input = pd.Series(gene_list_converted.values,index=gene_list_converted).to_dict()\n",
    "    else:\n",
    "        gene_list_converted, uniprot2input, not_converted = utils.convert_IDs(gene_list,id_type)\n",
    "    \n",
    "    #read in dictionary and the gocam sizes\n",
    "    x = pd.read_csv(gcs)\n",
    "    gocam_sizes = pd.Series(x.sizes.values,index=x.gocam)\n",
    "    Dict = utils.csv2dict(id2g)\n",
    "    \n",
    "    #call enrich()\n",
    "    ncHGT = False\n",
    "    if method == 'ncHGT':\n",
    "        ncHGT = True\n",
    "    #results: (filtered_out_genes, filtered_list, setID2members_input_uni, setID2members_input, df_display)\n",
    "    results = enrich(list(gene_list.g), gene_list_converted, uniprot2input, gocam_sizes, Dict, ncHGT = ncHGT, FDR=FDR,num_bins = num_bins)\n",
    "    \n",
    "    if display_gene_symbol == True:\n",
    "        results[4]['shared entities in gocam'] = utils.uniprot2gene(results[4]['shared entities in gocam'])\n",
    "        results[4]['shared entities in gocam'] = results[4]['shared entities in gocam'].apply(lambda x: [x_.replace('sset:','set:') for x_ in x])\n",
    "    if method == 'set' or method == 'ncHGT':\n",
    "        print(f\"Analysis run on {len(results[1])} entities from {len(gene_list)-len(results[0])} out of {len(gene_list)} input genes\")\n",
    "    \n",
    "\n",
    "    if return_all:\n",
    "        return (gene_list, *results)\n",
    "    else:\n",
    "        return results[4]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c41f8c-dfeb-444e-b5b2-7c51f2b10b9e",
   "metadata": {},
   "source": [
    "# testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f8217cf-3729-4db0-abf1-0ada9802336a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 98/98 [00:01<00:00, 83.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis run on 68 entities from 48 out of 118 input genes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>pval (uncorrected)</th>\n",
       "      <th># entities in list</th>\n",
       "      <th>#entities in model</th>\n",
       "      <th>shared entities in gocam</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Activation of Matrix Metalloproteinases - Reactome</td>\n",
       "      <td>2.712844e-07</td>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>[set:proMMP3 initial activators, set:proMMP8 initial activators, set:proMMP9 activating protease...</td>\n",
       "      <td>http://model.geneontology.org/R-HSA-1592389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cytosolic sulfonation of small molecules - Reactome</td>\n",
       "      <td>1.303727e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>[SULT2A1, set:SULTs active on DHEA, set:SULT dimers (T3), set:SULT dimers (T2), set:SULT1E1,2A1]</td>\n",
       "      <td>http://model.geneontology.org/R-HSA-156584</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  pval (uncorrected)  \\\n",
       "0   Activation of Matrix Metalloproteinases - Reactome        2.712844e-07   \n",
       "1  Cytosolic sulfonation of small molecules - Reactome        1.303727e-04   \n",
       "\n",
       "   # entities in list  #entities in model  \\\n",
       "0                   7                  18   \n",
       "1                   5                  19   \n",
       "\n",
       "                                                                              shared entities in gocam  \\\n",
       "0  [set:proMMP3 initial activators, set:proMMP8 initial activators, set:proMMP9 activating protease...   \n",
       "1     [SULT2A1, set:SULTs active on DHEA, set:SULT dimers (T3), set:SULT dimers (T2), set:SULT1E1,2A1]   \n",
       "\n",
       "                                           url  \n",
       "0  http://model.geneontology.org/R-HSA-1592389  \n",
       "1   http://model.geneontology.org/R-HSA-156584  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import enrich as enrich_\n",
    "\n",
    "govaere_1 = enrich_.enrich_wrapper('Goavere_S2.csv','Gene Symbol',method='ncHGT',FDR = 0.1,fpath = '../test_data/processed/')\n",
    "govaere_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fa836f9-14f2-48b1-84eb-ff07f97aedf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 98/98 [10:23<00:00,  6.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis run on 68 entities from 48 out of 118 input genes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>pval (uncorrected)</th>\n",
       "      <th># entities in list</th>\n",
       "      <th>#entities in model</th>\n",
       "      <th>shared entities in gocam</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Activation of Matrix Metalloproteinases - Reactome</td>\n",
       "      <td>2.684776e-07</td>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>[set:proMMP3 initial activators, set:proMMP8 initial activators, set:proMMP9 activating protease...</td>\n",
       "      <td>http://model.geneontology.org/R-HSA-1592389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cytosolic sulfonation of small molecules - Reactome</td>\n",
       "      <td>1.293896e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>[SULT2A1, set:SULTs active on DHEA, set:SULT dimers (T3), set:SULT dimers (T2), set:SULT1E1,2A1]</td>\n",
       "      <td>http://model.geneontology.org/R-HSA-156584</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  pval (uncorrected)  \\\n",
       "0   Activation of Matrix Metalloproteinases - Reactome        2.684776e-07   \n",
       "1  Cytosolic sulfonation of small molecules - Reactome        1.293896e-04   \n",
       "\n",
       "   # entities in list  #entities in model  \\\n",
       "0                   7                  18   \n",
       "1                   5                  19   \n",
       "\n",
       "                                                                              shared entities in gocam  \\\n",
       "0  [set:proMMP3 initial activators, set:proMMP8 initial activators, set:proMMP9 activating protease...   \n",
       "1     [SULT2A1, set:SULTs active on DHEA, set:SULT dimers (T3), set:SULT dimers (T2), set:SULT1E1,2A1]   \n",
       "\n",
       "                                           url  \n",
       "0  http://model.geneontology.org/R-HSA-1592389  \n",
       "1   http://model.geneontology.org/R-HSA-156584  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "govaere_2 = enrich_wrapper('Goavere_S2.csv','Gene Symbol',method='ncHGT',FDR = 0.1,num_bins = 2, fpath = '../test_data/processed/')\n",
    "govaere_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "568414f1-458d-4799-854a-22c66c90f6d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 482/482 [01:19<00:00,  6.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis run on 423 entities from 365 out of 1172 input genes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>pval (uncorrected)</th>\n",
       "      <th># entities in list</th>\n",
       "      <th>#entities in model</th>\n",
       "      <th>shared entities in gocam</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Collagen biosynthesis and modifying enzymes - Reactome</td>\n",
       "      <td>4.680930e-07</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>[PPIB, P3H1, PLOD3, P4HB, set:Prolyl 3-hydroxylases, set:Lysyl hydroxylases, set:Procollagen N-p...</td>\n",
       "      <td>http://model.geneontology.org/R-HSA-1650814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hedgehog ligand biogenesis - Reactome</td>\n",
       "      <td>4.690733e-06</td>\n",
       "      <td>13</td>\n",
       "      <td>50</td>\n",
       "      <td>[PSMD13, PSMA5, PSMD11, PSMA7, PSME2, PSMD4, PSMB1, PSMB7, PSMD8, PSMB5, P4HB, PSMB6, SYVN1]</td>\n",
       "      <td>http://model.geneontology.org/R-HSA-5358346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ER-Phagosome pathway - Reactome</td>\n",
       "      <td>5.123754e-06</td>\n",
       "      <td>13</td>\n",
       "      <td>51</td>\n",
       "      <td>[PSMD13, PSMA5, PSMD11, SEC61B, PSMA7, PSME2, PSMD4, PSMB1, PSMB7, PSMD8, PSMB5, PSMB6, set:SEC6...</td>\n",
       "      <td>http://model.geneontology.org/R-HSA-1236974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Regulation of APC/C activators between G1/S and early anaphase - Reactome</td>\n",
       "      <td>7.226495e-06</td>\n",
       "      <td>13</td>\n",
       "      <td>52</td>\n",
       "      <td>[PSMD13, PSMA5, PSMD11, PSMA7, PSME2, PSMD4, PSMB1, PSMB7, CDK1, PSMD8, PSMB5, PSMB6, set:CDC25]</td>\n",
       "      <td>http://model.geneontology.org/R-HSA-176408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Neddylation - Reactome</td>\n",
       "      <td>9.256658e-06</td>\n",
       "      <td>14</td>\n",
       "      <td>62</td>\n",
       "      <td>[UBE2M, PSMD13, PSMA5, PSMD11, PSMA7, PSME2, PSMD4, PSMB1, CUL9, PSMB7, PSMD8, PSMB5, PSMB6, set...</td>\n",
       "      <td>http://model.geneontology.org/R-HSA-8951664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Separation of Sister Chromatids - Reactome</td>\n",
       "      <td>8.704360e-04</td>\n",
       "      <td>11</td>\n",
       "      <td>63</td>\n",
       "      <td>[PSMD13, PSMA5, PSMD11, PSMA7, PSME2, PSMD4, PSMB1, PSMB7, PSMD8, PSMB5, PSMB6]</td>\n",
       "      <td>http://model.geneontology.org/R-HSA-2467813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>CDK-mediated phosphorylation and removal of Cdc6 - Reactome</td>\n",
       "      <td>1.441100e-03</td>\n",
       "      <td>11</td>\n",
       "      <td>65</td>\n",
       "      <td>[PSMD13, PSMA5, PSMD11, PSMA7, PSME2, PSMD4, PSMB1, PSMB7, PSMD8, PSMB5, PSMB6]</td>\n",
       "      <td>http://model.geneontology.org/R-HSA-69017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Interleukin-1 signaling - Reactome</td>\n",
       "      <td>1.727041e-03</td>\n",
       "      <td>11</td>\n",
       "      <td>64</td>\n",
       "      <td>[PSMD13, PSMA5, PSMD11, PSMA7, PSME2, PSMD4, PSMB1, PSMB7, PSMD8, PSMB5, PSMB6]</td>\n",
       "      <td>http://model.geneontology.org/R-HSA-9020702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Downstream TCR signaling - Reactome</td>\n",
       "      <td>1.813878e-03</td>\n",
       "      <td>14</td>\n",
       "      <td>74</td>\n",
       "      <td>[PSMD13, PSMA5, PSMD11, PSMA7, PSME2, PSMD4, PSMB1, PSMB7, PSMD8, PSMB5, PSMB6, CD3D, set:PIK3C(...</td>\n",
       "      <td>http://model.geneontology.org/R-HSA-202424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>A tetrasaccharide linker sequence is required for GAG synthesis - Reactome</td>\n",
       "      <td>5.201480e-03</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>[B3GAT3, B4GALT7, set:B3GAT dimers, set:XYLT1, XYLT2]</td>\n",
       "      <td>http://model.geneontology.org/R-HSA-1971475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                         title  \\\n",
       "0                       Collagen biosynthesis and modifying enzymes - Reactome   \n",
       "1                                        Hedgehog ligand biogenesis - Reactome   \n",
       "2                                              ER-Phagosome pathway - Reactome   \n",
       "3    Regulation of APC/C activators between G1/S and early anaphase - Reactome   \n",
       "4                                                       Neddylation - Reactome   \n",
       "..                                                                         ...   \n",
       "62                                  Separation of Sister Chromatids - Reactome   \n",
       "63                 CDK-mediated phosphorylation and removal of Cdc6 - Reactome   \n",
       "64                                          Interleukin-1 signaling - Reactome   \n",
       "65                                         Downstream TCR signaling - Reactome   \n",
       "66  A tetrasaccharide linker sequence is required for GAG synthesis - Reactome   \n",
       "\n",
       "    pval (uncorrected)  # entities in list  #entities in model  \\\n",
       "0         4.680930e-07                  10                  12   \n",
       "1         4.690733e-06                  13                  50   \n",
       "2         5.123754e-06                  13                  51   \n",
       "3         7.226495e-06                  13                  52   \n",
       "4         9.256658e-06                  14                  62   \n",
       "..                 ...                 ...                 ...   \n",
       "62        8.704360e-04                  11                  63   \n",
       "63        1.441100e-03                  11                  65   \n",
       "64        1.727041e-03                  11                  64   \n",
       "65        1.813878e-03                  14                  74   \n",
       "66        5.201480e-03                   4                   6   \n",
       "\n",
       "                                                                               shared entities in gocam  \\\n",
       "0   [PPIB, P3H1, PLOD3, P4HB, set:Prolyl 3-hydroxylases, set:Lysyl hydroxylases, set:Procollagen N-p...   \n",
       "1          [PSMD13, PSMA5, PSMD11, PSMA7, PSME2, PSMD4, PSMB1, PSMB7, PSMD8, PSMB5, P4HB, PSMB6, SYVN1]   \n",
       "2   [PSMD13, PSMA5, PSMD11, SEC61B, PSMA7, PSME2, PSMD4, PSMB1, PSMB7, PSMD8, PSMB5, PSMB6, set:SEC6...   \n",
       "3      [PSMD13, PSMA5, PSMD11, PSMA7, PSME2, PSMD4, PSMB1, PSMB7, CDK1, PSMD8, PSMB5, PSMB6, set:CDC25]   \n",
       "4   [UBE2M, PSMD13, PSMA5, PSMD11, PSMA7, PSME2, PSMD4, PSMB1, CUL9, PSMB7, PSMD8, PSMB5, PSMB6, set...   \n",
       "..                                                                                                  ...   \n",
       "62                      [PSMD13, PSMA5, PSMD11, PSMA7, PSME2, PSMD4, PSMB1, PSMB7, PSMD8, PSMB5, PSMB6]   \n",
       "63                      [PSMD13, PSMA5, PSMD11, PSMA7, PSME2, PSMD4, PSMB1, PSMB7, PSMD8, PSMB5, PSMB6]   \n",
       "64                      [PSMD13, PSMA5, PSMD11, PSMA7, PSME2, PSMD4, PSMB1, PSMB7, PSMD8, PSMB5, PSMB6]   \n",
       "65  [PSMD13, PSMA5, PSMD11, PSMA7, PSME2, PSMD4, PSMB1, PSMB7, PSMD8, PSMB5, PSMB6, CD3D, set:PIK3C(...   \n",
       "66                                                [B3GAT3, B4GALT7, set:B3GAT dimers, set:XYLT1, XYLT2]   \n",
       "\n",
       "                                            url  \n",
       "0   http://model.geneontology.org/R-HSA-1650814  \n",
       "1   http://model.geneontology.org/R-HSA-5358346  \n",
       "2   http://model.geneontology.org/R-HSA-1236974  \n",
       "3    http://model.geneontology.org/R-HSA-176408  \n",
       "4   http://model.geneontology.org/R-HSA-8951664  \n",
       "..                                          ...  \n",
       "62  http://model.geneontology.org/R-HSA-2467813  \n",
       "63    http://model.geneontology.org/R-HSA-69017  \n",
       "64  http://model.geneontology.org/R-HSA-9020702  \n",
       "65   http://model.geneontology.org/R-HSA-202424  \n",
       "66  http://model.geneontology.org/R-HSA-1971475  \n",
       "\n",
       "[67 rows x 6 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "platelet_up_1 = enrich_.enrich_wrapper('platelets_up.csv','Gene Symbol',method='ncHGT',FDR = 0.1,fpath = '../test_data/processed/')\n",
    "platelet_up_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c96c44f3-9aa5-4438-b647-457ed64df7ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▊                                         | 10/482 [00:03<03:03,  2.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9% done out of 12852 iterations\n",
      "19% done out of 12852 iterations\n",
      "29% done out of 12852 iterations\n",
      "39% done out of 12852 iterations\n",
      "49% done out of 12852 iterations\n",
      "59% done out of 12852 iterations\n",
      "69% done out of 12852 iterations\n",
      "79% done out of 12852 iterations\n",
      "89% done out of 12852 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▉                                       | 11/482 [00:33<1:14:28,  9.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99% done out of 12852 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|█▊                                        | 21/482 [00:50<13:01,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9% done out of 17232 iterations\n",
      "19% done out of 17232 iterations\n",
      "29% done out of 17232 iterations\n",
      "39% done out of 17232 iterations\n",
      "49% done out of 17232 iterations\n",
      "59% done out of 17232 iterations\n",
      "69% done out of 17232 iterations\n",
      "79% done out of 17232 iterations\n",
      "89% done out of 17232 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|██                                        | 24/482 [01:18<43:46,  5.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99% done out of 17232 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|███████▏                                  | 82/482 [01:39<02:26,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0% done out of 127080 iterations\n",
      "1% done out of 127080 iterations\n",
      "2% done out of 127080 iterations\n",
      "3% done out of 127080 iterations\n",
      "4% done out of 127080 iterations\n",
      "5% done out of 127080 iterations\n",
      "6% done out of 127080 iterations\n",
      "7% done out of 127080 iterations\n",
      "8% done out of 127080 iterations\n",
      "9% done out of 127080 iterations\n",
      "10% done out of 127080 iterations\n",
      "10% done out of 127080 iterations\n",
      "11% done out of 127080 iterations\n",
      "12% done out of 127080 iterations\n",
      "13% done out of 127080 iterations\n",
      "14% done out of 127080 iterations\n",
      "15% done out of 127080 iterations\n",
      "16% done out of 127080 iterations\n",
      "17% done out of 127080 iterations\n",
      "18% done out of 127080 iterations\n",
      "19% done out of 127080 iterations\n",
      "20% done out of 127080 iterations\n",
      "20% done out of 127080 iterations\n",
      "21% done out of 127080 iterations\n",
      "22% done out of 127080 iterations\n",
      "23% done out of 127080 iterations\n",
      "24% done out of 127080 iterations\n",
      "25% done out of 127080 iterations\n",
      "26% done out of 127080 iterations\n",
      "27% done out of 127080 iterations\n",
      "28% done out of 127080 iterations\n",
      "29% done out of 127080 iterations\n",
      "30% done out of 127080 iterations\n",
      "30% done out of 127080 iterations\n",
      "31% done out of 127080 iterations\n",
      "32% done out of 127080 iterations\n",
      "33% done out of 127080 iterations\n",
      "34% done out of 127080 iterations\n",
      "35% done out of 127080 iterations\n",
      "36% done out of 127080 iterations\n",
      "37% done out of 127080 iterations\n",
      "38% done out of 127080 iterations\n",
      "39% done out of 127080 iterations\n",
      "40% done out of 127080 iterations\n",
      "40% done out of 127080 iterations\n",
      "41% done out of 127080 iterations\n",
      "42% done out of 127080 iterations\n",
      "43% done out of 127080 iterations\n",
      "44% done out of 127080 iterations\n",
      "45% done out of 127080 iterations\n",
      "46% done out of 127080 iterations\n",
      "47% done out of 127080 iterations\n",
      "48% done out of 127080 iterations\n",
      "49% done out of 127080 iterations\n",
      "50% done out of 127080 iterations\n",
      "50% done out of 127080 iterations\n",
      "51% done out of 127080 iterations\n",
      "52% done out of 127080 iterations\n",
      "53% done out of 127080 iterations\n",
      "54% done out of 127080 iterations\n",
      "55% done out of 127080 iterations\n",
      "56% done out of 127080 iterations\n",
      "57% done out of 127080 iterations\n",
      "58% done out of 127080 iterations\n",
      "59% done out of 127080 iterations\n",
      "60% done out of 127080 iterations\n",
      "60% done out of 127080 iterations\n",
      "61% done out of 127080 iterations\n",
      "62% done out of 127080 iterations\n",
      "63% done out of 127080 iterations\n",
      "64% done out of 127080 iterations\n",
      "65% done out of 127080 iterations\n",
      "66% done out of 127080 iterations\n",
      "67% done out of 127080 iterations\n",
      "68% done out of 127080 iterations\n",
      "69% done out of 127080 iterations\n",
      "70% done out of 127080 iterations\n",
      "70% done out of 127080 iterations\n",
      "71% done out of 127080 iterations\n",
      "72% done out of 127080 iterations\n",
      "73% done out of 127080 iterations\n",
      "74% done out of 127080 iterations\n",
      "75% done out of 127080 iterations\n",
      "76% done out of 127080 iterations\n",
      "77% done out of 127080 iterations\n",
      "78% done out of 127080 iterations\n",
      "79% done out of 127080 iterations\n",
      "80% done out of 127080 iterations\n",
      "80% done out of 127080 iterations\n",
      "81% done out of 127080 iterations\n",
      "82% done out of 127080 iterations\n",
      "83% done out of 127080 iterations\n",
      "84% done out of 127080 iterations\n",
      "85% done out of 127080 iterations\n",
      "86% done out of 127080 iterations\n",
      "87% done out of 127080 iterations\n",
      "88% done out of 127080 iterations\n",
      "89% done out of 127080 iterations\n",
      "90% done out of 127080 iterations\n",
      "90% done out of 127080 iterations\n",
      "91% done out of 127080 iterations\n",
      "92% done out of 127080 iterations\n",
      "93% done out of 127080 iterations\n",
      "94% done out of 127080 iterations\n",
      "95% done out of 127080 iterations\n",
      "96% done out of 127080 iterations\n",
      "97% done out of 127080 iterations\n",
      "98% done out of 127080 iterations\n",
      "99% done out of 127080 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█████▊                            | 83/482 [1:11:56<132:08:43, 1192.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% done out of 127080 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███████████▊                           | 146/482 [1:13:02<09:44,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10% done out of 14040 iterations\n",
      "20% done out of 14040 iterations\n",
      "30% done out of 14040 iterations\n",
      "40% done out of 14040 iterations\n",
      "50% done out of 14040 iterations\n",
      "60% done out of 14040 iterations\n",
      "70% done out of 14040 iterations\n",
      "80% done out of 14040 iterations\n",
      "90% done out of 14040 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███████████▉                           | 148/482 [1:13:36<40:59,  7.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% done out of 14040 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|██████████████▍                        | 179/482 [1:14:01<07:48,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10% done out of 10860 iterations\n",
      "20% done out of 10860 iterations\n",
      "30% done out of 10860 iterations\n",
      "40% done out of 10860 iterations\n",
      "50% done out of 10860 iterations\n",
      "60% done out of 10860 iterations\n",
      "70% done out of 10860 iterations\n",
      "80% done out of 10860 iterations\n",
      "90% done out of 10860 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|██████████████▌                        | 180/482 [1:14:19<28:01,  5.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% done out of 10860 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|███████████████████▉                   | 246/482 [1:15:59<04:33,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10% done out of 28800 iterations\n",
      "20% done out of 28800 iterations\n",
      "30% done out of 28800 iterations\n",
      "40% done out of 28800 iterations\n",
      "50% done out of 28800 iterations\n",
      "60% done out of 28800 iterations\n",
      "70% done out of 28800 iterations\n",
      "80% done out of 28800 iterations\n",
      "90% done out of 28800 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|███████████████████                  | 248/482 [1:18:10<1:05:44, 16.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% done out of 28800 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|███████████████████████▏               | 286/482 [1:20:57<02:40,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9% done out of 60671 iterations\n",
      "19% done out of 60671 iterations\n",
      "29% done out of 60671 iterations\n",
      "39% done out of 60671 iterations\n",
      "49% done out of 60671 iterations\n",
      "59% done out of 60671 iterations\n",
      "69% done out of 60671 iterations\n",
      "79% done out of 60671 iterations\n",
      "89% done out of 60671 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████▍              | 287/482 [1:36:46<7:38:56, 141.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99% done out of 60671 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|████████████████████████████▌          | 353/482 [1:37:30<00:35,  3.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9% done out of 43197 iterations\n",
      "19% done out of 43197 iterations\n",
      "29% done out of 43197 iterations\n",
      "39% done out of 43197 iterations\n",
      "49% done out of 43197 iterations\n",
      "59% done out of 43197 iterations\n",
      "69% done out of 43197 iterations\n",
      "79% done out of 43197 iterations\n",
      "89% done out of 43197 iterations\n",
      "99% done out of 43197 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████████████████████████         | 362/482 [2:49:36<9:09:12, 274.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9% done out of 11253 iterations\n",
      "19% done out of 11253 iterations\n",
      "29% done out of 11253 iterations\n",
      "39% done out of 11253 iterations\n",
      "49% done out of 11253 iterations\n",
      "59% done out of 11253 iterations\n",
      "69% done out of 11253 iterations\n",
      "79% done out of 11253 iterations\n",
      "89% done out of 11253 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████████████████████████▎        | 365/482 [2:49:51<7:03:05, 216.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99% done out of 11253 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|█████████████████████████████████▊     | 418/482 [2:53:52<00:33,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9% done out of 17424 iterations\n",
      "19% done out of 17424 iterations\n",
      "29% done out of 17424 iterations\n",
      "39% done out of 17424 iterations\n",
      "49% done out of 17424 iterations\n",
      "59% done out of 17424 iterations\n",
      "69% done out of 17424 iterations\n",
      "79% done out of 17424 iterations\n",
      "89% done out of 17424 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|██████████████████████████████████▌    | 427/482 [2:55:03<04:34,  4.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99% done out of 17424 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 482/482 [3:01:04<00:00, 22.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis run on 423 entities from 365 out of 1172 input genes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>pval (uncorrected)</th>\n",
       "      <th># entities in list</th>\n",
       "      <th>#entities in model</th>\n",
       "      <th>shared entities in gocam</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Collagen biosynthesis and modifying enzymes - Reactome</td>\n",
       "      <td>5.245116e-07</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>[PPIB, P3H1, PLOD3, P4HB, set:Prolyl 3-hydroxylases, set:Lysyl hydroxylases, set:Procollagen N-p...</td>\n",
       "      <td>http://model.geneontology.org/R-HSA-1650814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hedgehog ligand biogenesis - Reactome</td>\n",
       "      <td>4.359699e-06</td>\n",
       "      <td>13</td>\n",
       "      <td>50</td>\n",
       "      <td>[PSMD13, PSMA5, PSMD11, PSMA7, PSME2, PSMD4, PSMB1, PSMB7, PSMD8, PSMB5, P4HB, PSMB6, SYVN1]</td>\n",
       "      <td>http://model.geneontology.org/R-HSA-5358346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ER-Phagosome pathway - Reactome</td>\n",
       "      <td>4.736527e-06</td>\n",
       "      <td>13</td>\n",
       "      <td>51</td>\n",
       "      <td>[PSMD13, PSMA5, PSMD11, SEC61B, PSMA7, PSME2, PSMD4, PSMB1, PSMB7, PSMD8, PSMB5, PSMB6, set:SEC6...</td>\n",
       "      <td>http://model.geneontology.org/R-HSA-1236974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Regulation of APC/C activators between G1/S and early anaphase - Reactome</td>\n",
       "      <td>6.615440e-06</td>\n",
       "      <td>13</td>\n",
       "      <td>52</td>\n",
       "      <td>[PSMD13, PSMA5, PSMD11, PSMA7, PSME2, PSMD4, PSMB1, PSMB7, CDK1, PSMD8, PSMB5, PSMB6, set:CDC25]</td>\n",
       "      <td>http://model.geneontology.org/R-HSA-176408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Neddylation - Reactome</td>\n",
       "      <td>8.065999e-06</td>\n",
       "      <td>14</td>\n",
       "      <td>62</td>\n",
       "      <td>[UBE2M, PSMD13, PSMA5, PSMD11, PSMA7, PSME2, PSMD4, PSMB1, CUL9, PSMB7, PSMD8, PSMB5, PSMB6, set...</td>\n",
       "      <td>http://model.geneontology.org/R-HSA-8951664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Separation of Sister Chromatids - Reactome</td>\n",
       "      <td>6.911030e-04</td>\n",
       "      <td>11</td>\n",
       "      <td>63</td>\n",
       "      <td>[PSMD13, PSMA5, PSMD11, PSMA7, PSME2, PSMD4, PSMB1, PSMB7, PSMD8, PSMB5, PSMB6]</td>\n",
       "      <td>http://model.geneontology.org/R-HSA-2467813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>CDK-mediated phosphorylation and removal of Cdc6 - Reactome</td>\n",
       "      <td>1.114502e-03</td>\n",
       "      <td>11</td>\n",
       "      <td>65</td>\n",
       "      <td>[PSMD13, PSMA5, PSMD11, PSMA7, PSME2, PSMD4, PSMB1, PSMB7, PSMD8, PSMB5, PSMB6]</td>\n",
       "      <td>http://model.geneontology.org/R-HSA-69017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Downstream TCR signaling - Reactome</td>\n",
       "      <td>1.311332e-03</td>\n",
       "      <td>14</td>\n",
       "      <td>74</td>\n",
       "      <td>[PSMD13, PSMA5, PSMD11, PSMA7, PSME2, PSMD4, PSMB1, PSMB7, PSMD8, PSMB5, PSMB6, CD3D, set:PIK3C(...</td>\n",
       "      <td>http://model.geneontology.org/R-HSA-202424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Interleukin-1 signaling - Reactome</td>\n",
       "      <td>1.327377e-03</td>\n",
       "      <td>11</td>\n",
       "      <td>64</td>\n",
       "      <td>[PSMD13, PSMA5, PSMD11, PSMA7, PSME2, PSMD4, PSMB1, PSMB7, PSMD8, PSMB5, PSMB6]</td>\n",
       "      <td>http://model.geneontology.org/R-HSA-9020702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>A tetrasaccharide linker sequence is required for GAG synthesis - Reactome</td>\n",
       "      <td>5.234366e-03</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>[B3GAT3, B4GALT7, set:B3GAT dimers, set:XYLT1, XYLT2]</td>\n",
       "      <td>http://model.geneontology.org/R-HSA-1971475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                         title  \\\n",
       "0                       Collagen biosynthesis and modifying enzymes - Reactome   \n",
       "1                                        Hedgehog ligand biogenesis - Reactome   \n",
       "2                                              ER-Phagosome pathway - Reactome   \n",
       "3    Regulation of APC/C activators between G1/S and early anaphase - Reactome   \n",
       "4                                                       Neddylation - Reactome   \n",
       "..                                                                         ...   \n",
       "62                                  Separation of Sister Chromatids - Reactome   \n",
       "63                 CDK-mediated phosphorylation and removal of Cdc6 - Reactome   \n",
       "64                                         Downstream TCR signaling - Reactome   \n",
       "65                                          Interleukin-1 signaling - Reactome   \n",
       "66  A tetrasaccharide linker sequence is required for GAG synthesis - Reactome   \n",
       "\n",
       "    pval (uncorrected)  # entities in list  #entities in model  \\\n",
       "0         5.245116e-07                  10                  12   \n",
       "1         4.359699e-06                  13                  50   \n",
       "2         4.736527e-06                  13                  51   \n",
       "3         6.615440e-06                  13                  52   \n",
       "4         8.065999e-06                  14                  62   \n",
       "..                 ...                 ...                 ...   \n",
       "62        6.911030e-04                  11                  63   \n",
       "63        1.114502e-03                  11                  65   \n",
       "64        1.311332e-03                  14                  74   \n",
       "65        1.327377e-03                  11                  64   \n",
       "66        5.234366e-03                   4                   6   \n",
       "\n",
       "                                                                               shared entities in gocam  \\\n",
       "0   [PPIB, P3H1, PLOD3, P4HB, set:Prolyl 3-hydroxylases, set:Lysyl hydroxylases, set:Procollagen N-p...   \n",
       "1          [PSMD13, PSMA5, PSMD11, PSMA7, PSME2, PSMD4, PSMB1, PSMB7, PSMD8, PSMB5, P4HB, PSMB6, SYVN1]   \n",
       "2   [PSMD13, PSMA5, PSMD11, SEC61B, PSMA7, PSME2, PSMD4, PSMB1, PSMB7, PSMD8, PSMB5, PSMB6, set:SEC6...   \n",
       "3      [PSMD13, PSMA5, PSMD11, PSMA7, PSME2, PSMD4, PSMB1, PSMB7, CDK1, PSMD8, PSMB5, PSMB6, set:CDC25]   \n",
       "4   [UBE2M, PSMD13, PSMA5, PSMD11, PSMA7, PSME2, PSMD4, PSMB1, CUL9, PSMB7, PSMD8, PSMB5, PSMB6, set...   \n",
       "..                                                                                                  ...   \n",
       "62                      [PSMD13, PSMA5, PSMD11, PSMA7, PSME2, PSMD4, PSMB1, PSMB7, PSMD8, PSMB5, PSMB6]   \n",
       "63                      [PSMD13, PSMA5, PSMD11, PSMA7, PSME2, PSMD4, PSMB1, PSMB7, PSMD8, PSMB5, PSMB6]   \n",
       "64  [PSMD13, PSMA5, PSMD11, PSMA7, PSME2, PSMD4, PSMB1, PSMB7, PSMD8, PSMB5, PSMB6, CD3D, set:PIK3C(...   \n",
       "65                      [PSMD13, PSMA5, PSMD11, PSMA7, PSME2, PSMD4, PSMB1, PSMB7, PSMD8, PSMB5, PSMB6]   \n",
       "66                                                [B3GAT3, B4GALT7, set:B3GAT dimers, set:XYLT1, XYLT2]   \n",
       "\n",
       "                                            url  \n",
       "0   http://model.geneontology.org/R-HSA-1650814  \n",
       "1   http://model.geneontology.org/R-HSA-5358346  \n",
       "2   http://model.geneontology.org/R-HSA-1236974  \n",
       "3    http://model.geneontology.org/R-HSA-176408  \n",
       "4   http://model.geneontology.org/R-HSA-8951664  \n",
       "..                                          ...  \n",
       "62  http://model.geneontology.org/R-HSA-2467813  \n",
       "63    http://model.geneontology.org/R-HSA-69017  \n",
       "64   http://model.geneontology.org/R-HSA-202424  \n",
       "65  http://model.geneontology.org/R-HSA-9020702  \n",
       "66  http://model.geneontology.org/R-HSA-1971475  \n",
       "\n",
       "[67 rows x 6 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "platelets_up_2 = enrich_wrapper('platelets_up.csv','Gene Symbol',method='ncHGT',FDR = 0.1,num_bins = 2, fpath = '../test_data/processed/')\n",
    "platelets_up_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "03a11caf-c716-42c0-b944-579a5fddf4b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.68092972e-07, 4.69073297e-06, 5.12375403e-06, 7.22649490e-06,\n",
       "       9.25665772e-06, 1.54031981e-05, 1.76723487e-05, 1.76723487e-05,\n",
       "       2.04477651e-05, 2.06935007e-05, 2.22590691e-05, 2.65148337e-05,\n",
       "       3.13001910e-05, 3.67237821e-05, 3.79456919e-05, 4.67514620e-05,\n",
       "       4.67514620e-05, 4.67514620e-05, 5.46593836e-05, 5.72454294e-05,\n",
       "       5.72454294e-05, 6.41823349e-05, 6.66666529e-05, 6.96834031e-05,\n",
       "       6.96834031e-05, 6.96834031e-05, 7.45309858e-05, 9.35713245e-05,\n",
       "       9.75082849e-05, 1.01557005e-04, 1.01557005e-04, 1.12455552e-04,\n",
       "       1.16992039e-04, 1.19021300e-04, 1.21651945e-04, 1.23514723e-04,\n",
       "       1.34465872e-04, 1.39671509e-04, 1.39671509e-04, 1.45013000e-04,\n",
       "       1.65955204e-04, 1.72283801e-04, 1.82634074e-04, 1.82634074e-04,\n",
       "       1.85032583e-04, 2.18364068e-04, 2.18364068e-04, 2.39017282e-04,\n",
       "       2.63830490e-04, 3.06824328e-04, 3.16614661e-04, 3.58051467e-04,\n",
       "       3.78960262e-04, 3.82858967e-04, 4.78510409e-04, 5.07244548e-04,\n",
       "       5.69523118e-04, 5.83344607e-04, 6.24372863e-04, 7.64074809e-04,\n",
       "       7.64074809e-04, 7.64074809e-04, 8.70436031e-04, 1.44110048e-03,\n",
       "       1.72704140e-03, 1.81387806e-03, 5.20148036e-03])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "platelet_up_1['pval (uncorrected)'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d7aacbb3-5b5c-48da-800c-060ae2de517a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([112.05286547,  92.94280405,  92.44251825,  91.54423976,\n",
       "        87.13726947,  89.20190067,  91.57272805,  91.57272805,\n",
       "        89.00370271,  91.2593891 ,  90.75939689,  88.11402686,\n",
       "        76.38640173,  89.83954303,  92.35486382,  91.62144562,\n",
       "        91.62144562,  91.62144562,  91.27711704,  90.89410643,\n",
       "        90.89410643,  87.97714372,  90.54931487,  90.17277904,\n",
       "        90.17277904,  90.17277904,  88.14470517,  89.47923336,\n",
       "        89.11197126,  88.74789489,  88.74789489,  88.76341972,\n",
       "        88.40228523,  89.50954374,  88.04420774,  95.8607299 ,\n",
       "        91.09360616,  87.69849539,  90.34473284,  87.34627157,\n",
       "        87.00053246,  84.49074116,  79.70246567,  79.73052659,\n",
       "        86.74701228,  86.05391089,  86.05391089,  85.28634026,\n",
       "        87.0523966 ,  84.55706741,  81.9771897 ,  74.51366033,\n",
       "        84.84532842,  97.96403516,  86.88415536,  89.37011409,\n",
       "        83.28680814,  82.17813799,  82.84065865,  80.03098027,\n",
       "        80.03098027,  80.03098027,  79.3973332 ,  77.33683581,\n",
       "        75.92937121,  73.17892735, 100.63222771])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percent_changes = platelets_up_2['pval (uncorrected)'].values/platelet_up_1['pval (uncorrected)'].values*100\n",
    "percent_changes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2d4580-67c2-4450-abc7-88aa75382819",
   "metadata": {},
   "source": [
    "Mean and standard deviations of percent changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3ca25b14-cb8d-4da1-9a82-5f213ee4da60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([75.4338724 , 88.74789489, 98.89790255])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.quantile(percent_changes,q=[.025,.50,.975])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d48ea9c7-d24f-4247-bec8-41bec27295bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 171/171 [00:02<00:00, 67.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis run on 122 entities from 103 out of 440 input genes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>pval (uncorrected)</th>\n",
       "      <th># entities in list</th>\n",
       "      <th>#entities in model</th>\n",
       "      <th>shared entities in gocam</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Activation of Matrix Metalloproteinases - Reactome</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>[MMP7, MMP2, set:MMP1,7, set:proMMP9 activating proteases, set:MMP2,3,7,10,11, set:MMP1 (2, 3, 7...</td>\n",
       "      <td>http://model.geneontology.org/R-HSA-1592389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  pval (uncorrected)  \\\n",
       "0  Activation of Matrix Metalloproteinases - Reactome            0.000024   \n",
       "\n",
       "   # entities in list  #entities in model  \\\n",
       "0                   7                  18   \n",
       "\n",
       "                                                                              shared entities in gocam  \\\n",
       "0  [MMP7, MMP2, set:MMP1,7, set:proMMP9 activating proteases, set:MMP2,3,7,10,11, set:MMP1 (2, 3, 7...   \n",
       "\n",
       "                                           url  \n",
       "0  http://model.geneontology.org/R-HSA-1592389  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hoang_fibrosis_set = enrich_.enrich_wrapper('Hoang_2019_fibrosis.csv','Gene Symbol',method='ncHGT',FDR = 0.1,fpath = '../test_data/processed/')\n",
    "hoang_fibrosis_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa7a6e9c-1f6c-470f-a30f-726c63749c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 171/171 [00:03<00:00, 55.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis run on 122 entities from 103 out of 440 input genes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>pval (uncorrected)</th>\n",
       "      <th># entities in list</th>\n",
       "      <th>#entities in model</th>\n",
       "      <th>shared entities in gocam</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Activation of Matrix Metalloproteinases - Reactome</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>[MMP7, MMP2, set:MMP1,7, set:proMMP9 activating proteases, set:MMP2,3,7,10,11, set:MMP1 (2, 3, 7...</td>\n",
       "      <td>http://model.geneontology.org/R-HSA-1592389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  pval (uncorrected)  \\\n",
       "0  Activation of Matrix Metalloproteinases - Reactome            0.000024   \n",
       "\n",
       "   # entities in list  #entities in model  \\\n",
       "0                   7                  18   \n",
       "\n",
       "                                                                              shared entities in gocam  \\\n",
       "0  [MMP7, MMP2, set:MMP1,7, set:proMMP9 activating proteases, set:MMP2,3,7,10,11, set:MMP1 (2, 3, 7...   \n",
       "\n",
       "                                           url  \n",
       "0  http://model.geneontology.org/R-HSA-1592389  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hoang_fibrosis_1 = enrich_wrapper('Hoang_2019_fibrosis.csv','Gene Symbol',num_bins =1, method='ncHGT',show_significant = False, FDR = 0.1,fpath = '../test_data/processed/')\n",
    "hoang_fibrosis_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4126ba3-b173-49d5-b149-b519d9643e23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "cb757ef9-0a65-4414-a419-5ec63fa05e31",
   "metadata": {},
   "source": [
    "hoang_fibrosis_3 = enrich_wrapper('Hoang_2019_fibrosis.csv','Gene Symbol',num_bins =3, method='ncHGT',FDR = 0.1,fpath = '../test_data/processed/')\n",
    "hoang_fibrosis_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faeaff1f-56f6-4a28-a93a-56088d94051d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hoang_fibrosis_2 = enrich_wrapper('Hoang_2019_fibrosis.csv','Gene Symbol',num_bins =2, method='ncHGT',show_significant = False, FDR = 0.1,fpath = '../test_data/processed/')\n",
    "hoang_fibrosis_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5252f92d-c712-42e2-a4a2-c6887805e2e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:gocam2]",
   "language": "python",
   "name": "conda-env-gocam2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
